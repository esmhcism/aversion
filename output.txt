manual seed: 1
{'base_mode': 'ft_cos',
 'batch_size_base': 128,
 'batch_size_new': 0,
 'dataroot': 'data/',
 'dataset': 'cub200',
 'debug': False,
 'decay': 0.0005,
 'epochs_base': 100,
 'epochs_new': 100,
 'gamma': 0.1,
 'gpu': '0',
 'lr_base': 1e-05,
 'lr_new': 0.1,
 'model_dir': 'checkpoint/cub.pth',
 'momentum': 0.9,
 'new_mode': 'ft_cos',
 'not_data_init': False,
 'num_workers': 8,
 'project': 'base',
 'seed': 1,
 'start_session': 0,
 'temperature': 16,
 'test_batch_size': 100}
use gpu: [0]
Model = DataParallel(
  (module): MYNET(
    (backbone): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      )
      (pos_drop): Dropout(p=0, inplace=False)
      (blocks): ModuleList(
        (0-11): 12 x Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0, inplace=False)
          )
          (tanh): Tanh()
        )
      )
      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (tanh): Tanh()
      (head): Linear(in_features=768, out_features=1000, bias=True)
    )
    (activation): Tanh()
    (ln): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)
    (fc): Linear(in_features=1000, out_features=200, bias=False)
  )
)
Loading init parameters from: checkpoint/cub.pth
Model = DataParallel(
  (module): MYNET(
    (backbone): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      )
      (pos_drop): Dropout(p=0, inplace=False)
      (blocks): ModuleList(
        (0-11): 12 x Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0, inplace=False)
          )
          (tanh): Tanh()
        )
      )
      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (tanh): Tanh()
      (head): Linear(in_features=768, out_features=1000, bias=True)
    )
    (activation): Tanh()
    (ln): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)
    (fc): Linear(in_features=1000, out_features=200, bias=False)
  )
)
Loading init parameters from: checkpoint/cub.pth
FLOPs(million):  17582.945224
parameters:  | name                           | #elements or shape   |
|:-------------------------------|:---------------------|
| model                          | 86.8M                |
|  module                        |  86.8M               |
|   module.backbone              |   86.6M              |
|    module.backbone.cls_token   |    (1, 1, 768)       |
|    module.backbone.pos_embed   |    (1, 197, 768)     |
|    module.backbone.patch_embed |    0.6M              |
|    module.backbone.blocks      |    85.1M             |
|    module.backbone.norm        |    1.5K              |
|    module.backbone.head        |    0.8M              |
|   module.ln                    |   2.0K               |
|    module.ln.weight            |    (1000,)           |
|    module.ln.bias              |    (1000,)           |
|   module.fc                    |   0.2M               |
|    module.fc.weight            |    (200, 1000)       |
epo 0, test, loss=0.4685 acc=0.8729
The new best test acc of base session=87.287
[87.287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Total time used 0.17 mins
testing session: [1]
epo 0, test, loss=0.4973 acc=0.8609
Saving model to :checkpoint/cub200/base/ft_cos-ft_cos-data_init-start_0/-T_16.00-ftLR_0.100-ftEpoch_100/session1_max_acc.pth
  test acc=86.094
[87.287, 86.094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Total time used 0.29 mins
testing session: [2]
epo 0, test, loss=0.5290 acc=0.8526
Saving model to :checkpoint/cub200/base/ft_cos-ft_cos-data_init-start_0/-T_16.00-ftLR_0.100-ftEpoch_100/session2_max_acc.pth
  test acc=85.257
[87.287, 86.094, 85.257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Total time used 0.43 mins
testing session: [3]
epo 0, test, loss=0.6173 acc=0.8311
Saving model to :checkpoint/cub200/base/ft_cos-ft_cos-data_init-start_0/-T_16.00-ftLR_0.100-ftEpoch_100/session3_max_acc.pth
  test acc=83.105
[87.287, 86.094, 85.257, 83.105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Total time used 0.57 mins
testing session: [4]
epo 0, test, loss=0.6220 acc=0.8344
Saving model to :checkpoint/cub200/base/ft_cos-ft_cos-data_init-start_0/-T_16.00-ftLR_0.100-ftEpoch_100/session4_max_acc.pth
  test acc=83.436
[87.287, 86.094, 85.257, 83.105, 83.436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Total time used 0.72 mins
testing session: [5]
epo 0, test, loss=0.6768 acc=0.8164
Saving model to :checkpoint/cub200/base/ft_cos-ft_cos-data_init-start_0/-T_16.00-ftLR_0.100-ftEpoch_100/session5_max_acc.pth
  test acc=81.640
[87.287, 86.094, 85.257, 83.105, 83.436, 81.64, 0.0, 0.0, 0.0, 0.0, 0.0]
Total time used 0.86 mins
testing session: [6]
epo 0, test, loss=0.6848 acc=0.8167
Saving model to :checkpoint/cub200/base/ft_cos-ft_cos-data_init-start_0/-T_16.00-ftLR_0.100-ftEpoch_100/session6_max_acc.pth
  test acc=81.675
[87.287, 86.094, 85.257, 83.105, 83.436, 81.64, 81.675, 0.0, 0.0, 0.0, 0.0]
Total time used 1.01 mins
testing session: [7]
epo 0, test, loss=0.7079 acc=0.8204
Saving model to :checkpoint/cub200/base/ft_cos-ft_cos-data_init-start_0/-T_16.00-ftLR_0.100-ftEpoch_100/session7_max_acc.pth
  test acc=82.040
[87.287, 86.094, 85.257, 83.105, 83.436, 81.64, 81.675, 82.04, 0.0, 0.0, 0.0]
Total time used 1.17 mins
testing session: [8]
epo 0, test, loss=0.7355 acc=0.8153
Saving model to :checkpoint/cub200/base/ft_cos-ft_cos-data_init-start_0/-T_16.00-ftLR_0.100-ftEpoch_100/session8_max_acc.pth
  test acc=81.528
[87.287, 86.094, 85.257, 83.105, 83.436, 81.64, 81.675, 82.04, 81.528, 0.0, 0.0]
Total time used 1.33 mins
testing session: [9]
epo 0, test, loss=0.7375 acc=0.8128
Saving model to :checkpoint/cub200/base/ft_cos-ft_cos-data_init-start_0/-T_16.00-ftLR_0.100-ftEpoch_100/session9_max_acc.pth
  test acc=81.277
[87.287, 86.094, 85.257, 83.105, 83.436, 81.64, 81.675, 82.04, 81.528, 81.277, 0.0]
Total time used 1.50 mins
testing session: [10]
epo 0, test, loss=0.7381 acc=0.8156
Saving model to :checkpoint/cub200/base/ft_cos-ft_cos-data_init-start_0/-T_16.00-ftLR_0.100-ftEpoch_100/session10_max_acc.pth
  test acc=81.563
[87.287, 86.094, 85.257, 83.105, 83.436, 81.64, 81.675, 82.04, 81.528, 81.277, 81.563]
Total time used 1.67 mins
